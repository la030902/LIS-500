<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Teachable Machine</title>
  <link rel="stylesheet" href="stylepage.css" />

  <!-- Required Libraries for p5.js + ml5.js -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.6.0/p5.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.6.0/addons/p5.dom.min.js"></script>
  <script src="https://unpkg.com/ml5@latest/dist/ml5.min.js"></script>
  

  <style>
    canvas {
      display: block;
      margin: 0 auto;
      margin-top: 30px;
    }
    #canvas-container {
      text-align: center;
    }
  </style>
</head>
<body>
  <nav>
    <div class="logo">LIS 500 Project</div>
    <ul class="nav-links">
      <li><a href="index.html">Welcome</a></li>
      <li><a href="about us.html">About</a></li>
      <li><a href="resource.html">Resources</a></li>
      <li><a href="tech hero.html">Tech Hero</a></li>
      <li><a href="teachable.html">Teachable Machines</a></li>
    </ul>
  </nav>

<section class="introduction">
  <div class="intro-container">
    <h2>Introduction</h2>
    <p>
      For this project, we built a simple web app that can recognize traffic signs using a webcam. We trained a model with Google’s Teachable Machine to identify three types of signs—stop, street, and yield—and then integrated it into a webpage using HTML, CSS, and JavaScript.
    </p>
    <p>
      At first, it just seemed like a fun, hands-on way to learn about machine learning. But as we tested it more, we started noticing how easily the model could get confused. Things like lighting, camera angle, or even slight differences between signs affected the results. That made us realize how tricky it is for machines to interpret the real world, even when the task seems straightforward.
    </p>
    <p>
      It also got us thinking about the bigger picture. In <em>Unmasking AI</em>, Joy Buolamwini talks about how biased data in facial recognition can lead to unfair or inaccurate outcomes. While our project was much smaller in scale, we still saw how important it is to have a diverse and well-balanced dataset. Our model sometimes misread signs simply because it hadn’t seen enough examples from different situations.
    </p>
    <p>
      Overall, this project gave us a deeper look into how machine learning works—and how much it relies on the data we feed it. Teaching a computer to recognize traffic signs sounds easy, but it turns out there’s a lot more going on behind the scenes.
    </p>
  </div>
</section>


  
  <section id="canvas-container">
    <h2>Live Video Classifier</h2>
    <p id="label-display">Label: <span id="label">waiting...</span></p>
  </section>
 
<section>
  <h2>Project Statement</h2>
  <div class="reflection-grid">
    <div class="reflection-box">
      <h3>Joan Lee</h3>
      <p>This project...</p>
    </div>
    <div class="reflection-box">
      <h3>Ann Teoh</h3>
      <p>...</p>
    </div>
    <div class="reflection-box">
      <h3>Madison Sveum</h3>
      <p>...</p>
    </div>
  </div>
</section>


  <script src="sketch.js"></script>

  <footer>
    <p>&copy; Joan Lee, Madison Sveum, Ann Teoh. LIS 500 Project2</p>
  </footer>


</body>
</html>
